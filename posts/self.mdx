---
title: "self"
authors: [
  {
    name: "noreplydev"
  }, 
]
category: ["-"]
id: "hello, friend"
date: "2025-08-04"
---

# The Problem Is the Output Type, Not the Output

*__self__* is a virtual machine designed to integrate AI instructions as
part of the instruction set. Making the AI a first class citizen instruction in the VM. 
Think of V8 or the JVM, that lets you do things like: 

> NOTE: Every code snippet in this post is real, functional code.

```swift
import ai

let actions = ai.do("
infer the value of 'hello world!' in Chinese and
create a file called demo.txt and put the content
on it.
")

fn exec_action(item) {
    println("executing action: ", item)
    item.exec()
}

actions.map(exec_action)
```

That code creates demo.txt, containing "hello world!" in Chinese. How? It uses the _self_ standard library
 as the available functions to execute. The output looks like this:

```
executing action: Action(ai.infer)
executing action: Action(fs.write_file)
```

The potential here is huge, because it doesn’t just execute the function. It returns a vector of **Action** structs, and you 
decide whether to execute each **Action** or not, for example, based on whether the operation is destructive.

<br/>

But is this the real potential of a virtual machine with native AI integration at the machine level? That’s the real question. 
AI opens up an entirely new world of solutions for semantic, contextual, and non-discretizable problems.

> NOTE: In this post, "AI" will be used interchangeably with Large Language Models, as one implementation of AI. This distinction matters because future branches of AI could enable new usage patterns.

### AI impact on deterministic software

One common concern is the lack of determinism in AI outputs. How does a stochastically generated 
output fit into environments that require determinism? Internally, models are deterministic given 
the same state and seed, but for the consumer the output cannot be guaranteed or controlled in that way. 
And that’s exactly the point: we don’t need AI to operate in deterministic systems. 
We need it to solve semantic, contextual, and non-discretizable problems.

<br/>

For decades we’ve been able to process PDFs, but now with AI we can infer if a PDF talks about "pink cats".
How could we do that without AI? Raw PDF parsing? N-gram generation? Keyword matching? Tag extraction? In practice, 
all of this was just deterministic execution based on heuristics. The PDF example is simple, but what about program
execution? Isn’t it essentially the same?

<br/>

Let’s go back to what a program is. Turing described a "Turing machine" as a sliced tape processor, where each tape
slice means something. The whole tape is the program. Now imagine our tape for printing "hello world" looks like this:

```
// two tape slices
["hello world"]-[PRINT]
```

Historically the tape contained instructions like _LOAD_ or _JUMP_ to manage data and control flow. Now imagine adding a new
instruction type: _INFER_. Technically _INFER_ can mean anything we define, but the powerful thing is to make it an _AI instruction_,
unlike _PRINT_, which deterministically outputs a value, `INFER` allows you to generate an inference of a value based on some input.
For example:

```
// two tape slices
["a random color"]-[INFER]  -> "red"
```

In this context, the _INFER_ non-deterministic output shines, it could infer values based on runtime context or on non-discretizable problems.
So why do we often assume AI cannot be used as a native program instruction? The thing is, **the problem is the output type, not the output**.

<br/>

Imagine we’re talking with random people, is the problem whether they say "house" or "home"? Or whether they say "house" and "casa" (Spanish for "house")?
In that case, the output is the word, but the **type** is the language. With AI, we often try to enforce "house" vs "home," but the real question is: can 
we enforce or cast whether the AI is answering in English or Spanish? 

### *self*

*__self__* implements a type system where each AI instruction returns a typed response. If it fails, *__self__* falls back to a *nothing* type or the enforced 
type. With this approach, *__self__* enables control flow based on AI instructions return values. Since these values are generated at runtime (though caching
could make them deterministic), we can build dynamic control flow based on semantics or context, such as:

```
import ai

let input = "' or 1=1--"
if ai.infer("does <arg> input looks like an sql injection?", input) {
  println("warning!")
} else {
  println("secure!")
}
```

Imagine setting this code snippet in front of a database query engine. Or consider a file-search example based on semantic topics:

```
import fs 

let search_topic = "cats"
let files = fs.read_dir("./files")

fn iter_files(file) {
  let file_path = path.join("./files", file)
  let content = fs.read_file(file_path)
  if ai.infer("<arg> content talks about " + search_topic + "?", content) {
    println("new found at: " + file_path)
  }
}

files.map(iter_files)
```

At this point, it could appear the question: what distinguishes *__self__* from a library on top of any other virtual machine?

### *self* as backend

*__self__* is a virtual machine. But how do we actually write code for it? _**ego**_. _ego_ is a programming language built for *__self__*, but it’s not the 
only option. _ego_ works as a frontend that compiles to _self_, but you could also imagine a compiler from a web UI, or even from Python, to *__self__* bytecode. 
In other words, *__self__* is the backend, the infrastructure for programs with native AI integration. Currently, *__self__* relies on state-of-the-art AI models from
providers like OpenAI and MistralAI, while also allowing you to plug in different providers or even define your own.

<br/>

The *__self__* virtual machine is built in Rust, which means it can be compiled to run on the browser, on mobile devices, on desktop, and even on microcontrollers
like the ESP32. Imagine an ESP32 with native AI integration for contextual control flow.

<br/>

All of this is possible because *__self__* is its own virtual machine. Achieving the same with just
a simple JavaScript library would be almost impossible. *__self__*  is built from scratch with zero 
axioms about what a virtual machine with native AI instructions should or
shouldn’t be.
 
<br/>

This is only the beginning of a wide range of possibilities that could be built with native integration of AI at a virtual machine level.
*__self__* is actively under development, and soon there will be closed releases available to try out. join the self [discord](https://discord.gg/WFpPHKM9Dz) to be among the first
people to experiment with it. 

<br/>

Goodbye, friend.

<br/>
<br/>